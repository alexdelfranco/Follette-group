{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banyan Sigma:\n",
    "## Get Bayesian probabilities for membership in young associations\n",
    "\n",
    "### Requirements:\n",
    "Data file with, at minimum, RA, DEC, PMRA, PMDEC, EPMRA (the error), and EPMDEC. Parallax (labeled PLX), radial velocity and its error (RV, ERV), and many other parameters are optional.\n",
    "\n",
    "I'm using Gaia data that Beck had already pulled for the distance re-estimates. It resolved ~360 of the stars in the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import the python file\n",
    "import importlib, banyan_sigma\n",
    "importlib.reload(banyan_sigma)\n",
    "\n",
    "#import the main function from the file\n",
    "from banyan_sigma import banyan_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv (made in a separate folder and then moved to here)\n",
    "# (Gaia data, trimmed to just the columns we need)\n",
    "stars = pd.read_csv('follette_banyansigma_input.csv')\n",
    "\n",
    "#get rid of weird first column\n",
    "stars.drop(labels='Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "#rename the columns to Banyan Sigma preferred names\n",
    "#(can also make a dictionary with your column name and their preferred, but this is easier)\n",
    "stars.columns = ['NAME','RA','DEC','PMRA','PMDEC','EPMRA','EPMDEC','RV','ERV','PLX','EPLX']\n",
    "\n",
    "#remove rows with negative parallax values, which are clearly unphysical\n",
    "#(removes 6 negative plx values and 28 with nan values)\n",
    "stars = stars[stars['PLX']>0]\n",
    "\n",
    "#reset index of stars. drop other index column and do so in place.\n",
    "stars.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#glimpse data\n",
    "#we recover 327 stars.\n",
    "stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Banyan Sigma Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function: need the data, and setting use parallax and rv to True\n",
    "# the membership probs will take plx and rv into account when they're available\n",
    "banyansigma_output = banyan_sigma(stars_data=stars, use_plx=True, use_rv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the output has a LOT of columns and sub-structures. We're interested in:\n",
    "1. The most probable association for each star (or field, if that's most probable)\n",
    "2. The membership probability for that association (or for the field)\n",
    "\n",
    "To get there, we'll use two keys (like columns, but they are structures themselves) of the output structure:\n",
    "\n",
    "1. ALL: \"A structure that contains the Bayesian probability (0 to 1) for each of the associations (as individual keys).\" (from the README.md file)\n",
    "2. BEST_HYP: \"Most probable Bayesian hypothesis (including the field)\"\n",
    "\n",
    "In the future, we might want to look at METRICS to better understand the strength of these results. For now, this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate output structure to the relevant keys\n",
    "membership_probs = banyansigma_output[['ALL','BEST_HYP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull the membership probability for the most probable association.\n",
    "\n",
    "#empty lists for best probability and best hypothesis\n",
    "#easier to put into output csv\n",
    "BEST_HYP = []\n",
    "BEST_PROB = []\n",
    "\n",
    "\n",
    "#run through each row\n",
    "for i in np.arange(0,len(stars),1):\n",
    "    \n",
    "    #get best hypothesis\n",
    "    best_hyp = membership_probs['BEST_HYP']['Global'][i]\n",
    "    best_prob = membership_probs['ALL'][best_hyp][i]\n",
    "    \n",
    "    BEST_PROB.append(best_prob)\n",
    "    BEST_HYP.append(best_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars['BEST_PROB'] = BEST_PROB\n",
    "stars['BEST_HYP'] = BEST_HYP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kinda unnecessary adding and then re-filtering\n",
    "#but it's not a computation time problem so it's fine\n",
    "stars_mem_probs = stars[['NAME','BEST_HYP','BEST_PROB']]\n",
    "stars_mem_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write names, best hypothesis, and the probability to a CSV\n",
    "stars_mem_probs.to_csv('follette_membership_probabilities.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
